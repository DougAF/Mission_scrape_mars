{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'splinter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8585fd0d504c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#import pymongo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msplinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBrowser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msplinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mElementDoesNotExist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'splinter'"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "#import pymongo\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 1 : title and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "url = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "marsnasagov_soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch lists of HTML data\n",
    "results_title = marsnasagov_soup.find_all('div',class_=\"content_title\")\n",
    "results_p = marsnasagov_soup.find_all('div', class_='rollover_description_inner')\n",
    "#Check fetch\n",
    "display(len(results_title),\n",
    "        len(results_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init empty lists\n",
    "titles_list = []\n",
    "ptext_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab all paragraphs\n",
    "for paragraph in results_p:\n",
    "    ptext_list.append(paragraph.text)\n",
    "\n",
    "#grab all titles\n",
    "for title in results_title:\n",
    "    titles_list.append(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate most recent\n",
    "latest_title = titles_list[0]\n",
    "latest_paragraph = ptext_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 2: featured image (jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome driver and Splinter\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "#Splinter navigate to site, find the image url for the current Featured Mars Image\n",
    "browser.visit(url)\n",
    "browser.click_link_by_id('full_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch HTML for list creation\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "featured_image_url_find = soup.find('img', class_ = 'fancybox-image')\n",
    "featured_image_url_find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combines root of url with new found 'Featured image'\n",
    "featured_image_url = 'https://www.jpl.nasa.gov' + featured_image_url_find['src']\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 3: TWITTER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome driver and Splinter\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fetch HTML for list creation\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "#grab all tweets\n",
    "tweet_container_list = soup.find_all('div', class_ = 'js-tweet-text-container')\n",
    "\n",
    "#find latest tweet container\n",
    "tweet_container_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = []\n",
    "for tweet_container in tweet_container_list:\n",
    "    tweets_list.append(tweet_container.p.text.replace('\\n', ' ').split('hPapic.twitter.com/', 1)[0])\n",
    "    \n",
    "   \n",
    "#Store tweet\n",
    "mars_weather = tweets_list[0]\n",
    "mars_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 4 : mars facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas scrape facts table Diameter, Mass, etc.\n",
    "url = \"https://space-facts.com/mars/\"\n",
    "mars_facts_tables = pd.read_html(url)\n",
    "#grab table from list\n",
    "mars_facts_df = mars_facts_tables[0]\n",
    "mars_facts_df.columns = ['Measurement', 'Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_facts_df_indexed = mars_facts_df.set_index('Measurement')\n",
    "mars_facts_df_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas convert data to HTML table string.\n",
    "mars_facts_html = mars_facts_df_indexed.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mars_facts_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 5 : hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome driver and Splinter\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "soup = bs(response.text, 'html.parser')\n",
    "hemi_links_list_raw = soup.find_all('a', class_ = 'itemLink product-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init title and link lists \n",
    "hemi_links_title_list = []\n",
    "hemi_links_href_list = []\n",
    "# Identify and return link to listing\n",
    "#link = result.a['href']\n",
    "for link in hemi_links_list_raw:\n",
    "    hemi_links_title_list.append(link.text)\n",
    "    hemi_links_href_list.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    hemi_links_list_raw[0],\n",
    "    hemi_links_title_list,\n",
    "    hemi_links_href_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete image URLs\n",
    "hemi_full_url_list = []\n",
    "url_root = 'https://astrogeology.usgs.gov'\n",
    "for url_tail in hemi_links_href_list:\n",
    "    hemi_full_url_list.append(url_root + url_tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemi_full_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemi_jpg_list = []\n",
    "#full resolution image urls\n",
    "for url in hemi_full_url_list:\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text,'html.parser')\n",
    "    #fetch full image(class =\"wide-image\")\n",
    "    wide_image = soup.find('img', class_ = 'wide-image')\n",
    "    hemi_jpg_list.append(url_root + wide_image['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemi_jpg_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_titles_list = []\n",
    "for title in hemi_links_title_list:\n",
    "    clean_titles_list.append(title.split('Enhanced')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_titles_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hemi_dict_list = []\n",
    "for i in range(len(clean_titles_list)):\n",
    "    hemi_dict_list.append(dict(zip(clean_titles_list[i:i+1], hemi_jpg_list[i:i+1])))\n",
    "3hemi_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{e[0], e[1]} for e in zip(a,b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_titles_list[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "##### FOR DB AND APP PORTION ########\n",
    "#####################################\n",
    "\n",
    "# Define database and collection\n",
    "db = client.craigslist_db\n",
    "collection = db.items\n",
    "\n",
    "# URL of page to be scraped\n",
    "url = 'https://newjersey.craigslist.org/search/sss?sort=rel&query=guitar'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "response = requests.get(url)\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "# Examine the results, then determine element that contains sought info\n",
    "# results are returned as an iterable list\n",
    "results = soup.find_all('li', class_='result-row')\n",
    "\n",
    "# Loop through returned results\n",
    "for result in results:\n",
    "    # Error handling\n",
    "    try:\n",
    "        # Identify and return title of listing\n",
    "        title = result.find('a', class_='result-title').text\n",
    "        # Identify and return price of listing\n",
    "        price = result.a.span.text\n",
    "        # Identify and return link to listing\n",
    "        link = result.a['href']\n",
    "\n",
    "        # Run only if title, price, and link are available\n",
    "        if (title and price and link):\n",
    "            # Print results\n",
    "            print('-------------')\n",
    "            print(title)\n",
    "            print(price)\n",
    "            print(link)\n",
    "\n",
    "            # Dictionary to be inserted as a MongoDB document\n",
    "            post = {\n",
    "                'title': title,\n",
    "                'price': price,\n",
    "                'url': link\n",
    "            }\n",
    "            collection.insert_one(post)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "# Define database and collection\n",
    "db = client.craigslist_db\n",
    "collection = db.items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
